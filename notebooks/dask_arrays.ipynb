{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eaed28f-99a0-4435-b092-871a10453a76",
   "metadata": {},
   "source": [
    "# Dask arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cf1cd-8a9e-4c4b-88b3-c4d1fa5c03ad",
   "metadata": {},
   "source": [
    "Dask provides arrays, that are internally broken into **chunks** and processed in parallel\n",
    "- Numpy-like arrays\n",
    "- Pandas-like dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e16bcd-f5b6-4a83-bad8-65a542e38b34",
   "metadata": {},
   "source": [
    "# 1) Dask (Numpy-like) arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2ebfe-565a-4b29-a8c3-d938805d9f53",
   "metadata": {},
   "source": [
    "## 1.1) Understanding Numpy's limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5af2de6-5762-4fef-9a77-144a72706233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory error! Unable to allocate 74.5 GiB for an array with shape (100000, 100000) and data type float64\n"
     ]
    }
   ],
   "source": [
    "# Having a large array that fits entirely in RAM makes it inefficient for computation\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    large_array = np.ones((100000, 100000), dtype=np.float64)\n",
    "except Exception as e:\n",
    "    print(\"Memory error!\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d1964e-6c44-48fd-b9fb-9dea8112a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<ones_like, shape=(100000, 100000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "# Let's do it with Dask, which creates arrays using CHUNKING\n",
    "import dask.array as da\n",
    "\n",
    "# Here we specify that Dask must break the array in chunks of 1000 x 1000\n",
    "size = 100000\n",
    "dask_array = da.ones((size, size), chunks=(1000,1000) ,dtype=np.float64)\n",
    "print(dask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8a65a3-eed8-4f4e-9143-535dcebc35d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<ones_like, shape=(100000, 100000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "print(dask_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194f520-5e90-4733-83a0-cc5b9592eb14",
   "metadata": {},
   "source": [
    "## 1.2) Converting a Numpy array to Dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853dd9fe-433f-4a3c-8580-74969417663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<array, shape=(10000, 10000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "np_array = np.ones((10000, 10000), dtype=np.float64)\n",
    "dask_from_numpy = da.from_array(np_array, chunks=(1000,1000))\n",
    "print(dask_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63323bbf-a21d-4a48-b7cd-91291d6090a1",
   "metadata": {},
   "source": [
    "## 1.3) Converting a Dask array back to Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd66cf-d648-45b7-be4d-7d85dc1ccb29",
   "metadata": {},
   "source": [
    "You have to call the **compute()** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc8a576-c54e-4f3d-ab52-2066698befbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "np_result = dask_from_numpy.compute()\n",
    "print(np_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9631ff-0cab-4e27-be2c-c52e41955817",
   "metadata": {},
   "source": [
    "# 2) Dask (Pandas-like) Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2104f-a01e-49e6-b875-9b6b46802ed3",
   "metadata": {},
   "source": [
    "The same issues of memory limitations are overcome by Dask. It also replaces single-thread computation by parallel computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3423021-7d98-42c9-8c7d-3ceb2ca322f4",
   "metadata": {},
   "source": [
    "## 2.1) Pandas dataframe limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe37e9a-6fe7-4de9-93c0-33cdcaab8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import dask.dataframe as dd # you have to install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e22eeee-0cf5-48dd-b6b6-5fc9be3f9053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_id</th>\n",
       "      <th>system_public_name</th>\n",
       "      <th>site_location</th>\n",
       "      <th>timezone_or_utc_offset</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>dc_capacity_kW</th>\n",
       "      <th>kg_climate</th>\n",
       "      <th>pvcz_composite</th>\n",
       "      <th>...</th>\n",
       "      <th>number_records</th>\n",
       "      <th>dataset_size_mb</th>\n",
       "      <th>available_sensor_channels</th>\n",
       "      <th>qa_status</th>\n",
       "      <th>qa_issue</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Residential 1a</td>\n",
       "      <td>Lakewood, CO</td>\n",
       "      <td>America/Denver</td>\n",
       "      <td>39.7214</td>\n",
       "      <td>-105.0972</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>2.912</td>\n",
       "      <td>Dfb</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>13685898.0</td>\n",
       "      <td>313.25</td>\n",
       "      <td>7</td>\n",
       "      <td>fail</td>\n",
       "      <td>less than 1.0 years data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Residential 1b</td>\n",
       "      <td>Lakewood, CO</td>\n",
       "      <td>America/Denver</td>\n",
       "      <td>39.7214</td>\n",
       "      <td>-105.0972</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>2.720</td>\n",
       "      <td>Dfb</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12668178.0</td>\n",
       "      <td>289.95</td>\n",
       "      <td>7</td>\n",
       "      <td>fail</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>NREL x-Si -1</td>\n",
       "      <td>Golden, CO</td>\n",
       "      <td>7</td>\n",
       "      <td>39.7406</td>\n",
       "      <td>-105.1774</td>\n",
       "      <td>1795.3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>BSk</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>113978017.0</td>\n",
       "      <td>2608.75</td>\n",
       "      <td>15</td>\n",
       "      <td>pass</td>\n",
       "      <td>Filtered time series less than 1.0 years data,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>NREL CIS -1</td>\n",
       "      <td>Golden, CO</td>\n",
       "      <td>7</td>\n",
       "      <td>39.7404</td>\n",
       "      <td>-105.1774</td>\n",
       "      <td>1792.8</td>\n",
       "      <td>1.120</td>\n",
       "      <td>BSk</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>113103574.0</td>\n",
       "      <td>2588.74</td>\n",
       "      <td>14</td>\n",
       "      <td>pass</td>\n",
       "      <td>Filtered time series less than 1.0 years data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Silicor Materials</td>\n",
       "      <td>Golden, CO</td>\n",
       "      <td>7</td>\n",
       "      <td>39.7404</td>\n",
       "      <td>-105.1772</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>2.400</td>\n",
       "      <td>BSk</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>113673602.0</td>\n",
       "      <td>2601.78</td>\n",
       "      <td>15</td>\n",
       "      <td>pass</td>\n",
       "      <td>Percent clipping exceeded threshold of 10%, Fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   system_id system_public_name site_location timezone_or_utc_offset  \\\n",
       "0          2     Residential 1a  Lakewood, CO         America/Denver   \n",
       "1          3     Residential 1b  Lakewood, CO         America/Denver   \n",
       "2          4       NREL x-Si -1    Golden, CO                      7   \n",
       "3         10        NREL CIS -1    Golden, CO                      7   \n",
       "4         33  Silicor Materials    Golden, CO                      7   \n",
       "\n",
       "   latitude  longitude  elevation_m  dc_capacity_kW kg_climate  \\\n",
       "0   39.7214  -105.0972       1675.0           2.912        Dfb   \n",
       "1   39.7214  -105.0972       1675.0           2.720        Dfb   \n",
       "2   39.7406  -105.1774       1795.3           1.000        BSk   \n",
       "3   39.7404  -105.1774       1792.8           1.120        BSk   \n",
       "4   39.7404  -105.1772       1794.0           2.400        BSk   \n",
       "\n",
       "   pvcz_composite  ...  number_records  dataset_size_mb  \\\n",
       "0              12  ...      13685898.0           313.25   \n",
       "1              12  ...      12668178.0           289.95   \n",
       "2              12  ...     113978017.0          2608.75   \n",
       "3              12  ...     113103574.0          2588.74   \n",
       "4              12  ...     113673602.0          2601.78   \n",
       "\n",
       "   available_sensor_channels  qa_status  \\\n",
       "0                          7       fail   \n",
       "1                          7       fail   \n",
       "2                         15       pass   \n",
       "3                         14       pass   \n",
       "4                         15       pass   \n",
       "\n",
       "                                            qa_issue Unnamed: 26  Unnamed: 27  \\\n",
       "0                           less than 1.0 years data         NaN          NaN   \n",
       "1                                               <NA>         NaN          NaN   \n",
       "2  Filtered time series less than 1.0 years data,...         NaN          NaN   \n",
       "3      Filtered time series less than 1.0 years data         NaN          NaN   \n",
       "4  Percent clipping exceeded threshold of 10%, Fi...         NaN          NaN   \n",
       "\n",
       "   Unnamed: 28 Unnamed: 29 Unnamed: 30  \n",
       "0          NaN         NaN         NaN  \n",
       "1          NaN         NaN         NaN  \n",
       "2          NaN         NaN         NaN  \n",
       "3          NaN         NaN         NaN  \n",
       "4          NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a big file with Pandas produces an error. \n",
    "# Doing it with Dask\n",
    "\n",
    "df = dd.read_csv(\"../data/systems_20250729.csv\", dtype={'number_records': 'float64'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb007c89-007a-45eb-8b04-0d8f1509a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "system_id                              int64\n",
       "system_public_name           string[pyarrow]\n",
       "site_location                string[pyarrow]\n",
       "timezone_or_utc_offset       string[pyarrow]\n",
       "latitude                             float64\n",
       "longitude                            float64\n",
       "elevation_m                          float64\n",
       "dc_capacity_kW                       float64\n",
       "kg_climate                   string[pyarrow]\n",
       "pvcz_composite                         int64\n",
       "pvcz_t_rack                            int64\n",
       "pvcz_t_roof                            int64\n",
       "pvcz_humidity                          int64\n",
       "pvcz_wind                              int64\n",
       "tracking                     string[pyarrow]\n",
       "type                         string[pyarrow]\n",
       "azimuth                              float64\n",
       "tilt                                 float64\n",
       "first_timestamp              string[pyarrow]\n",
       "last_timestamp               string[pyarrow]\n",
       "years                                float64\n",
       "number_records                       float64\n",
       "dataset_size_mb                      float64\n",
       "available_sensor_channels              int64\n",
       "qa_status                    string[pyarrow]\n",
       "qa_issue                     string[pyarrow]\n",
       "Unnamed: 26                          float64\n",
       "Unnamed: 27                          float64\n",
       "Unnamed: 28                          float64\n",
       "Unnamed: 29                          float64\n",
       "Unnamed: 30                          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The interface is that same as pandas\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af0cfa35-62b0-4ce9-94c1-410082e981a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['system_id', 'system_public_name', 'site_location',\n",
       "       'timezone_or_utc_offset', 'latitude', 'longitude', 'elevation_m',\n",
       "       'dc_capacity_kW', 'kg_climate', 'pvcz_composite', 'pvcz_t_rack',\n",
       "       'pvcz_t_roof', 'pvcz_humidity', 'pvcz_wind', 'tracking', 'type',\n",
       "       'azimuth', 'tilt', 'first_timestamp', 'last_timestamp', 'years',\n",
       "       'number_records', 'dataset_size_mb', 'available_sensor_channels',\n",
       "       'qa_status', 'qa_issue', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28',\n",
       "       'Unnamed: 29', 'Unnamed: 30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ad8c5-28e0-46f1-91ab-7f203831b45a",
   "metadata": {},
   "source": [
    "## 2.2) Performing computations on arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db4533-545f-414a-b949-a83c827d465c",
   "metadata": {},
   "source": [
    "Here again, you have to call **compute()**  (lazy evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7244da7d-60a4-445c-8dcd-08610438c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "system_id                       0\n",
       "system_public_name              0\n",
       "site_location                 240\n",
       "timezone_or_utc_offset          0\n",
       "latitude                        0\n",
       "longitude                       0\n",
       "elevation_m                     0\n",
       "dc_capacity_kW                 65\n",
       "kg_climate                    240\n",
       "pvcz_composite                  0\n",
       "pvcz_t_rack                     0\n",
       "pvcz_t_roof                     0\n",
       "pvcz_humidity                   0\n",
       "pvcz_wind                       0\n",
       "tracking                      241\n",
       "type                          241\n",
       "azimuth                       241\n",
       "tilt                          290\n",
       "first_timestamp                 2\n",
       "last_timestamp                  2\n",
       "years                           2\n",
       "number_records                  2\n",
       "dataset_size_mb                 2\n",
       "available_sensor_channels       0\n",
       "qa_status                       0\n",
       "qa_issue                     1403\n",
       "Unnamed: 26                  1862\n",
       "Unnamed: 27                  1862\n",
       "Unnamed: 28                  1862\n",
       "Unnamed: 29                  1862\n",
       "Unnamed: 30                  1862\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: isnull() This function indicates whether values are missing (NaN in numeric arrays, None etc)\n",
    "# We can check the number of missing values per columns\n",
    "df.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5ca90-cdf7-4728-8751-b435d76beb27",
   "metadata": {},
   "source": [
    "# 3) Dask bags: managing Python objects that do not fit in tabular format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827440e-5b75-4a11-b70b-6010a00a9b03",
   "metadata": {},
   "source": [
    "Ideal for undtructured/semi-structured data like json, text files and logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa0ac3-25b0-42ab-96f4-07bc83af6c00",
   "metadata": {},
   "source": [
    "## 3.1) Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c657d5a-dbcb-4f35-8433-073422cf5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 21:54:38,910 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 84d8052f834899d2b9780ee6ad2bf54e initialized by task ('shuffle-transfer-84d8052f834899d2b9780ee6ad2bf54e', 0) executed on worker tcp://127.0.0.1:40567\n",
      "2025-11-06 21:54:39,430 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 84d8052f834899d2b9780ee6ad2bf54e deactivated due to stimulus 'task-erred-1762462479.4199512'\n"
     ]
    }
   ],
   "source": [
    "# ex: large json files or Python objects\n",
    "# For this, starting a Dask Client is optional but recommended\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb6b4d8-6d03-4d59-8905-df1eccdfeb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<mimesis, npartitions=10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os\n",
    "import dask\n",
    "# the mimesis module has to be installed with pip\n",
    "\n",
    "datadir = \"../data\"\n",
    "\n",
    "# Dask provides in-built datasets fro testing purposes\n",
    "data = dask.datasets.make_people()  # records from random people\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4760028b-af2d-40c6-8a08-5ee87f6aa6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': 69,\n",
       "  'name': ('Murray', 'Barber'),\n",
       "  'occupation': 'Jewellery',\n",
       "  'telephone': '+1-620-622-8516',\n",
       "  'address': {'address': '1117 Bitting Rapids', 'city': 'Ashwaubenon'},\n",
       "  'credit-card': {'number': '3460 341934 81399', 'expiration-date': '04/17'}},\n",
       " {'age': 7,\n",
       "  'name': ('Joe', 'Stevens'),\n",
       "  'occupation': 'Minicab Driver',\n",
       "  'telephone': '+1-623-953-1143',\n",
       "  'address': {'address': '420 Lisbon Court', 'city': 'Pinole'},\n",
       "  'credit-card': {'number': '5243 3396 4233 7529',\n",
       "   'expiration-date': '09/20'}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets have a look\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a672b1-b067-4289-8565-d10cc97b94a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nicolas/CODE/daskscratch/notebooks/../data/json/0.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/1.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/2.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/3.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/4.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/5.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/6.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/7.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/8.json',\n",
       " '/home/nicolas/CODE/daskscratch/notebooks/../data/json/9.json']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This saves the generated records as json files in the data directory\n",
    "data.map(json.dumps).to_textfiles(os.path.join(datadir,'json/*.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ac577-dc6e-4e09-bb62-cf811b1eac75",
   "metadata": {},
   "source": [
    "## 3.2) generating bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c66ee6e-8073-450d-a165-26d8cf2f6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c34aa06-0c44-461d-aa85-0f0c4d91c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<bag-from-delayed, npartitions=10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the json files previously generated\n",
    "b = db.read_text(os.path.join(datadir, 'json/*.json'))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b552c3c2-79d7-4d9e-aa4e-92c79bc5249a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<loads, npartitions=10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert them to Python dicts\n",
    "d = b.map(json.loads)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "034793bd-be08-4bfa-8d5c-7b03dcb709b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': 69,\n",
       "  'name': ['Murray', 'Barber'],\n",
       "  'occupation': 'Jewellery',\n",
       "  'telephone': '+1-620-622-8516',\n",
       "  'address': {'address': '1117 Bitting Rapids', 'city': 'Ashwaubenon'},\n",
       "  'credit-card': {'number': '3460 341934 81399', 'expiration-date': '04/17'}},\n",
       " {'age': 7,\n",
       "  'name': ['Joe', 'Stevens'],\n",
       "  'occupation': 'Minicab Driver',\n",
       "  'telephone': '+1-623-953-1143',\n",
       "  'address': {'address': '420 Lisbon Court', 'city': 'Pinole'},\n",
       "  'credit-card': {'number': '5243 3396 4233 7529',\n",
       "   'expiration-date': '09/20'}},\n",
       " {'age': 104,\n",
       "  'name': ['Conchita', 'Walter'],\n",
       "  'occupation': 'Purchase Ledger Clerk',\n",
       "  'telephone': '+17640929468',\n",
       "  'address': {'address': '457 Kinzey Walk', 'city': 'Casper'},\n",
       "  'credit-card': {'number': '4939 6561 1326 9994',\n",
       "   'expiration-date': '08/19'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look, what we have is a list of dicts\n",
    "d.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcc6ce-9e7f-4f45-8477-67ebab3544b1",
   "metadata": {},
   "source": [
    "## 3.3) Mapping and filtering data in bags  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e710819a-2b08-4c47-b28c-c932df2f1bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': 69,\n",
       "  'name': ['Murray', 'Barber'],\n",
       "  'occupation': 'Jewellery',\n",
       "  'telephone': '+1-620-622-8516',\n",
       "  'address': {'address': '1117 Bitting Rapids', 'city': 'Ashwaubenon'},\n",
       "  'credit-card': {'number': '3460 341934 81399', 'expiration-date': '04/17'}},\n",
       " {'age': 104,\n",
       "  'name': ['Conchita', 'Walter'],\n",
       "  'occupation': 'Purchase Ledger Clerk',\n",
       "  'telephone': '+17640929468',\n",
       "  'address': {'address': '457 Kinzey Walk', 'city': 'Casper'},\n",
       "  'credit-card': {'number': '4939 6561 1326 9994',\n",
       "   'expiration-date': '08/19'}},\n",
       " {'age': 53,\n",
       "  'name': ['Jolyn', 'Rogers'],\n",
       "  'occupation': 'Ambulance Controller',\n",
       "  'telephone': '+17728816113',\n",
       "  'address': {'address': '397 Harry Canyon', 'city': 'Hagerstown'},\n",
       "  'credit-card': {'number': '3478 017032 46101', 'expiration-date': '07/16'}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dask bags allow us to perform operations such as filtering, mapping and aggregation\n",
    "\n",
    "# Ex: filter records for age > 30 years  usong FILTER\n",
    "filtered = d.filter(lambda record: record['age']>30).take(3)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbcdd1e0-bd75-4a7b-9be8-4ac524ccdb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Jewellery',\n",
       " 'Minicab Driver',\n",
       " 'Purchase Ledger Clerk',\n",
       " 'Ambulance Controller',\n",
       " 'Ambulance Driver')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract specific records using MAP\n",
    "d.map(lambda record: record['occupation']).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa11f2-db08-40d2-bf0d-59ee368187c0",
   "metadata": {},
   "source": [
    "## 3.4) Computations with bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8abf6e03-f6be-4335-b585-0144d879cdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computation (lazy evaluation)\n",
    "\n",
    "d.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a29d3e6a-9da8-41a4-bb4c-bbe31eec46ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Jewellery',\n",
       " 'Purchase Ledger Clerk',\n",
       " 'Ambulance Controller',\n",
       " 'Palaeontologist',\n",
       " 'Hospital Technician')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chaining operations\n",
    "# Combining the two previous operations\n",
    "\n",
    "d.filter(lambda record: record['age']>30).map(lambda record: record['occupation']).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4874dceb-7fe0-4c0e-ae15-1ee5e17b2b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lift Attendant', 18),\n",
       " ('Analytical Chemist', 17),\n",
       " ('Labelling Operator', 17),\n",
       " ('Land Surveyor', 16),\n",
       " ('Maintenance Fitter', 16),\n",
       " ('Payroll Clerk', 15),\n",
       " ('Bailiff', 15),\n",
       " ('Watchmaker', 15),\n",
       " ('Glass Worker', 15),\n",
       " ('Repairer', 14)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The compute() operation generates a list\n",
    "result = d.filter(lambda record: record['age']>30).map(lambda record: record['occupation']).frequencies(sort=True).topk(10,key=1).compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd2fec-0113-48c7-8686-e32e09ba5a14",
   "metadata": {},
   "source": [
    "## 3.5) Storing processed bag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74301321-dda8-4fa7-939d-c88c1ce94ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<dumps, npartitions=10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you don't have to call compute(),it remains a bag object\n",
    "result_bag = d.filter(lambda record: record['age']>50)\n",
    "\n",
    "# Now you can json dump it (it is still a bag\n",
    "result_json = result_bag.map(json.dumps)\n",
    "result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f681f019-98b2-472d-b631-cfa0e7ad7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it to json text files\n",
    "result_json = result_json.to_textfiles(os.path.join(datadir, \"json/processed/*.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632120db-24ba-4b3a-a8a4-2cf78cad6628",
   "metadata": {},
   "source": [
    "## 3.6) Converting Dask bags to Dask dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4450edb-2a68-408a-9bd7-00007ce73159",
   "metadata": {},
   "source": [
    "It is necessary to **flatten** the data first (i.e, remove nested structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73e7488e-d0cc-461a-9b04-d1377bff801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(record):\n",
    "    return{\n",
    "        'age': record['age'],\n",
    "        'occupation': record['occupation'],\n",
    "        'telephone': record['telephone'],\n",
    "        'credit-card-number': record['credit-card']['number'],\n",
    "        'credit-card-expiration': record['credit-card']['expiration-date'],\n",
    "        'name': ' '.join(record['name']),\n",
    "        'street-address': record['address']['address'],\n",
    "        'city': record['address']['city'], \n",
    "    \n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca46254b-1ee9-44b2-bcb0-d4a8acfa4ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<filter-lambda, npartitions=10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23c7b4e4-028a-41ba-a2df-5a72282062cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': 69,\n",
       "  'occupation': 'Jewellery',\n",
       "  'telephone': '+1-620-622-8516',\n",
       "  'credit-card-number': '3460 341934 81399',\n",
       "  'credit-card-expiration': '04/17',\n",
       "  'name': 'Murray Barber',\n",
       "  'street-address': '1117 Bitting Rapids',\n",
       "  'city': 'Ashwaubenon'},\n",
       " {'age': 104,\n",
       "  'occupation': 'Purchase Ledger Clerk',\n",
       "  'telephone': '+17640929468',\n",
       "  'credit-card-number': '4939 6561 1326 9994',\n",
       "  'credit-card-expiration': '08/19',\n",
       "  'name': 'Conchita Walter',\n",
       "  'street-address': '457 Kinzey Walk',\n",
       "  'city': 'Casper'},\n",
       " {'age': 53,\n",
       "  'occupation': 'Ambulance Controller',\n",
       "  'telephone': '+17728816113',\n",
       "  'credit-card-number': '3478 017032 46101',\n",
       "  'credit-card-expiration': '07/16',\n",
       "  'name': 'Jolyn Rogers',\n",
       "  'street-address': '397 Harry Canyon',\n",
       "  'city': 'Hagerstown'},\n",
       " {'age': 85,\n",
       "  'occupation': 'Palaeontologist',\n",
       "  'telephone': '+13207796874',\n",
       "  'credit-card-number': '3751 367748 29518',\n",
       "  'credit-card-expiration': '12/22',\n",
       "  'name': 'Layla Albert',\n",
       "  'street-address': '400 Hawthorne Shore',\n",
       "  'city': 'Rock Hill'},\n",
       " {'age': 84,\n",
       "  'occupation': 'Sand Blaster',\n",
       "  'telephone': '+1-848-170-5520',\n",
       "  'credit-card-number': '4935 9784 9147 9811',\n",
       "  'credit-card-expiration': '03/18',\n",
       "  'name': 'Queenie Glenn',\n",
       "  'street-address': '776 Merrie Point',\n",
       "  'city': 'Biddeford'})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it on our bag object, display the 5 first records\n",
    "result_dico = result_bag.map(flatten).take(5)\n",
    "result_dico # Which is a tuple of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f0db334-222d-4094-9d6b-52e21ca1a996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 22:00:00,769 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 0)\n",
      "State:     executing\n",
      "Task:  <Task ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 0) _execute_subgraph(...)>\n",
      "Exception: 'AttributeError(\"partially initialized module \\'pandas\\' has no attribute \\'core\\' (most likely due to a circular import)\")'\n",
      "Traceback: '  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py\", line 2612, in to_dataframe\\n    import pandas as pd\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py\", line 139, in <module>\\n    from pandas import testing\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py\", line 6, in <module>\\n    from pandas._testing import (\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py\", line 405, in <module>\\n    cython_table = pd.core.common._cython_table.items()\\n                   ^^^^^^^\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ok so let's convert this flattened bag object into a dask dataframe\u001b[39;00m\n\u001b[32m      2\u001b[39m df2 = result_bag.map(flatten).to_dataframe()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/dataframe/dask_expr/_collection.py:692\u001b[39m, in \u001b[36mFrameBase.head\u001b[39m\u001b[34m(self, n, npartitions, compute)\u001b[39m\n\u001b[32m    690\u001b[39m out = new_collection(expr.Head(\u001b[38;5;28mself\u001b[39m, n=n, npartitions=npartitions))\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m     out = \u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/base.py:373\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py:2612\u001b[39m, in \u001b[36mto_dataframe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dataframe\u001b[39m(seq, columns, dtypes):\n\u001b[32m-> \u001b[39m\u001b[32m2612\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m   2613\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[32m   2615\u001b[39m     seq = reify(seq)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py:139\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    122\u001b[39m     concat,\n\u001b[32m    123\u001b[39m     lreshape,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     qcut,\n\u001b[32m    136\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[32m    144\u001b[39m     ExcelFile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     read_spss,\n\u001b[32m    173\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPublic testing utility functions.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     assert_extension_array_equal,\n\u001b[32m      8\u001b[39m     assert_frame_equal,\n\u001b[32m      9\u001b[39m     assert_index_equal,\n\u001b[32m     10\u001b[39m     assert_series_equal,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_extension_array_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_frame_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_series_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_index_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py:405\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytest\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest.raises(expected_exception, match=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m cython_table = pd.core.common._cython_table.items()\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[33;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[33;03m    keys and expected result.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Ok so let's convert this flattened bag object into a dask dataframe\n",
    "df2 = result_bag.map(flatten).to_dataframe()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44fd2158-739e-4f0c-b85c-3db2e20e9f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.dask_expr._collection.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e8ac051-fdc3-4511-a0c6-b735422dcf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 21:59:17,234 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 9)\n",
      "State:     executing\n",
      "Task:  <Task ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 9) _execute_subgraph(...)>\n",
      "Exception: 'AttributeError(\"partially initialized module \\'pandas\\' has no attribute \\'core\\' (most likely due to a circular import)\")'\n",
      "Traceback: '  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py\", line 2612, in to_dataframe\\n    import pandas as pd\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py\", line 139, in <module>\\n    from pandas import testing\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py\", line 6, in <module>\\n    from pandas._testing import (\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py\", line 405, in <module>\\n    cython_table = pd.core.common._cython_table.items()\\n                   ^^^^^^^\\n'\n",
      "\n",
      "2025-11-06 21:59:17,244 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 3)\n",
      "State:     executing\n",
      "Task:  <Task ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 3) _execute_subgraph(...)>\n",
      "Exception: 'AttributeError(\"partially initialized module \\'pandas\\' has no attribute \\'core\\' (most likely due to a circular import)\")'\n",
      "Traceback: '  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py\", line 2612, in to_dataframe\\n    import pandas as pd\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py\", line 139, in <module>\\n    from pandas import testing\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py\", line 6, in <module>\\n    from pandas._testing import (\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py\", line 405, in <module>\\n    cython_table = pd.core.common._cython_table.items()\\n                   ^^^^^^^\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/base.py:373\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py:2612\u001b[39m, in \u001b[36mto_dataframe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dataframe\u001b[39m(seq, columns, dtypes):\n\u001b[32m-> \u001b[39m\u001b[32m2612\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m   2613\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[32m   2615\u001b[39m     seq = reify(seq)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py:139\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    122\u001b[39m     concat,\n\u001b[32m    123\u001b[39m     lreshape,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     qcut,\n\u001b[32m    136\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[32m    144\u001b[39m     ExcelFile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     read_spss,\n\u001b[32m    173\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPublic testing utility functions.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     assert_extension_array_equal,\n\u001b[32m      8\u001b[39m     assert_frame_equal,\n\u001b[32m      9\u001b[39m     assert_index_equal,\n\u001b[32m     10\u001b[39m     assert_series_equal,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_extension_array_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_frame_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_series_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_index_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py:405\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytest\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest.raises(expected_exception, match=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m cython_table = pd.core.common._cython_table.items()\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[33;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[33;03m    keys and expected result.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "df2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4585f569-d3c7-44a5-9204-476447dde4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 21:55:50,622 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 2)\n",
      "State:     executing\n",
      "Task:  <Task ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 2) _execute_subgraph(...)>\n",
      "Exception: 'AttributeError(\"partially initialized module \\'pandas\\' has no attribute \\'core\\' (most likely due to a circular import)\")'\n",
      "Traceback: '  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py\", line 2612, in to_dataframe\\n    import pandas as pd\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py\", line 139, in <module>\\n    from pandas import testing\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py\", line 6, in <module>\\n    from pandas._testing import (\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py\", line 405, in <module>\\n    cython_table = pd.core.common._cython_table.items()\\n                   ^^^^^^^\\n'\n",
      "\n",
      "2025-11-06 21:55:50,628 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 9)\n",
      "State:     executing\n",
      "Task:  <Task ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 9) _execute_subgraph(...)>\n",
      "Exception: 'AttributeError(\"partially initialized module \\'pandas\\' has no attribute \\'core\\' (most likely due to a circular import)\")'\n",
      "Traceback: '  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py\", line 2612, in to_dataframe\\n    import pandas as pd\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py\", line 139, in <module>\\n    from pandas import testing\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py\", line 6, in <module>\\n    from pandas._testing import (\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py\", line 405, in <module>\\n    cython_table = pd.core.common._cython_table.items()\\n                   ^^^^^^^\\n'\n",
      "\n",
      "2025-11-06 21:55:50,644 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 0)\n",
      "State:     executing\n",
      "Task:  <Task ('bag-from-delayed-file_to_blocks-filter-lambda-flatten-list-loads-to_dataframe-1296ef8ce75a2966443e6992e0f79f39', 0) _execute_subgraph(...)>\n",
      "Exception: 'AttributeError(\"partially initialized module \\'pandas\\' has no attribute \\'core\\' (most likely due to a circular import)\")'\n",
      "Traceback: '  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py\", line 2612, in to_dataframe\\n    import pandas as pd\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py\", line 139, in <module>\\n    from pandas import testing\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py\", line 6, in <module>\\n    from pandas._testing import (\\n  File \"/home/nicolas/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py\", line 405, in <module>\\n    cython_table = pd.core.common._cython_table.items()\\n                   ^^^^^^^\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Now performing some computation of the dataframe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mage\u001b[49m\u001b[43m>\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/base.py:373\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/dask/bag/core.py:2612\u001b[39m, in \u001b[36mto_dataframe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_dataframe\u001b[39m(seq, columns, dtypes):\n\u001b[32m-> \u001b[39m\u001b[32m2612\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m   2613\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[32m   2615\u001b[39m     seq = reify(seq)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/__init__.py:139\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    122\u001b[39m     concat,\n\u001b[32m    123\u001b[39m     lreshape,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     qcut,\n\u001b[32m    136\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[32m    144\u001b[39m     ExcelFile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     read_spss,\n\u001b[32m    173\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/testing.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPublic testing utility functions.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     assert_extension_array_equal,\n\u001b[32m      8\u001b[39m     assert_frame_equal,\n\u001b[32m      9\u001b[39m     assert_index_equal,\n\u001b[32m     10\u001b[39m     assert_series_equal,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_extension_array_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_frame_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_series_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_index_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/daskscratch-x6OfnjBx-py3.12/lib/python3.12/site-packages/pandas/_testing/__init__.py:405\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytest\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest.raises(expected_exception, match=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m cython_table = pd.core.common._cython_table.items()\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[33;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[33;03m    keys and expected result.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "#Now performing some computation of the dataframe\n",
    "df2[df2.age>50].isna().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6ac4a-1cee-49d3-a0ba-b7f7cd71757a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
